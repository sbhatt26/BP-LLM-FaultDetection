{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunnybhatt/opt/anaconda3/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2024-12-16 17:29:11.595277: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing specifications...\n",
      "Processing complete. Reports generated.\n",
      "Gap report: /Users/sunnybhatt/Desktop/BPLLLMDEMO/specifications_gap_report.txt\n",
      "Improvement suggestions: /Users/sunnybhatt/Desktop/BPLLLMDEMO/specifications_improvements.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "base_dir = \"path/to/base\"\n",
    "\n",
    "readme_path = os.path.join(base_dir, \"README.txt\")\n",
    "groundtruth_path = os.path.join(base_dir, \"nonconforming-material-report-form.txt\")\n",
    "faulty_path = os.path.join(base_dir, \"faulty-nonconforming-material-report-form.txt\")\n",
    "fault_description_path = os.path.join(base_dir, \"fault-description.xml\")\n",
    "\n",
    "report_file_path = os.path.join(base_dir, \"specifications_gap_report.txt\")\n",
    "improvements_file_path = os.path.join(base_dir, \"specifications_improvements.txt\")\n",
    "\n",
    "embedding_model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "def load_lines_from_file(file_path):\n",
    "    \"\"\"Load lines from a text file, stripping whitespace and ignoring empty lines.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "    return lines\n",
    "\n",
    "def generate_entity_embeddings(entities):\n",
    "    return [{\"text\": entity, \"embedding\": embedding_model.encode(entity)} for entity in entities if entity.strip()]\n",
    "\n",
    "def detect_faults(reference_entities, faulty_entities):\n",
    "    embeddings = (\n",
    "        [{\"source\": \"reference\", **e} for e in reference_entities] +\n",
    "        [{\"source\": \"faulty\", **e} for e in faulty_entities]\n",
    "    )\n",
    "\n",
    "    if not embeddings:\n",
    "        return []\n",
    "\n",
    "    embedding_vectors = np.array([e[\"embedding\"] for e in embeddings])\n",
    "    clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=1.0).fit(embedding_vectors)\n",
    "\n",
    "    for idx, cluster_id in enumerate(clustering.labels_):\n",
    "        embeddings[idx][\"cluster\"] = cluster_id\n",
    "\n",
    "    clusters = defaultdict(list)\n",
    "    for embedding in embeddings:\n",
    "        clusters[embedding[\"cluster\"]].append(embedding)\n",
    "\n",
    "    faults = []\n",
    "    for cluster_id, members in clusters.items():\n",
    "        reference_members = [m for m in members if m[\"source\"] == \"reference\"]\n",
    "        faulty_members = [m for m in members if m[\"source\"] == \"faulty\"]\n",
    "        if not faulty_members and reference_members:\n",
    "            # Missing specs from reference\n",
    "            faults.append({\"type\": \"missing\", \"cluster\": cluster_id, \"entities\": reference_members})\n",
    "        elif not reference_members and faulty_members:\n",
    "            # Redundant specs in faulty file\n",
    "            faults.append({\"type\": \"redundant\", \"cluster\": cluster_id, \"entities\": faulty_members})\n",
    "\n",
    "    return faults\n",
    "\n",
    "def suggest_improvements_batch(faults, readme_text, fault_description_xml,\n",
    "                               groundtruth_name=\"nonconforming-material-report-form\",\n",
    "                               faulty_name=\"faulty-nonconforming-material-report-form\"):\n",
    "    \"\"\"\n",
    "    Suggest improvements for all faults in one go using Ollama.\n",
    "    Incorporate README and fault-description.xml content into the prompt.\n",
    "    \"\"\"\n",
    "\n",
    "    if not faults:\n",
    "        return []\n",
    "\n",
    "    missing_topics = [\", \".join([entity[\"text\"] for entity in f[\"entities\"]]) \n",
    "                      for f in faults if f[\"type\"] == \"missing\"]\n",
    "    redundant_topics = [\", \".join([entity[\"text\"] for entity in f[\"entities\"]]) \n",
    "                        for f in faults if f[\"type\"] == \"redundant\"]\n",
    "\n",
    "    prompt_parts = []\n",
    "    prompt_parts.append(\"Below are instructions and context for improving specifications.\\n\\n\")\n",
    "    prompt_parts.append(\"README:\\n\")\n",
    "    prompt_parts.append(readme_text + \"\\n\\n\")\n",
    "    prompt_parts.append(\"Fault Descriptions (from XML):\\n\")\n",
    "    prompt_parts.append(fault_description_xml + \"\\n\\n\")\n",
    "\n",
    "    prompt_parts.append(f\"Groundtruth Specifications Name: {groundtruth_name}\\n\")\n",
    "    prompt_parts.append(f\"Faulty Specifications Name: {faulty_name}\\n\\n\")\n",
    "\n",
    "    if missing_topics:\n",
    "        prompt_parts.append(\"The following important reference (groundtruth) specs are missing in the faulty file:\\n\")\n",
    "        for mt in missing_topics:\n",
    "            prompt_parts.append(f\"- {mt}\\n\")\n",
    "\n",
    "    if redundant_topics:\n",
    "        prompt_parts.append(\"\\nThe following specs might be redundant or not aligned with the groundtruth:\\n\")\n",
    "        for rt in redundant_topics:\n",
    "            prompt_parts.append(f\"- {rt}\\n\")\n",
    "\n",
    "    prompt_parts.append(\"\\nSuggest improvements to align the faulty specifications with best practices in specification design, as per the groundtruth and the fault descriptions above. \"\n",
    "                        \"Please detail how to address missing and redundant specifications.\\n\")\n",
    "\n",
    "    prompt = \"\".join(prompt_parts)\n",
    "\n",
    "    # Ollama request\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": \"mistral\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        suggestion_text = result.get(\"response\", \"\").strip()\n",
    "    else:\n",
    "        suggestion_text = \"No suggestion generated due to an error.\"\n",
    "\n",
    "    improvement_suggestions = [{\n",
    "        \"fault_type\": \"mixed\",\n",
    "        \"topics\": \"Multiple listed above\",\n",
    "        \"suggestion\": suggestion_text\n",
    "    }]\n",
    "\n",
    "    return improvement_suggestions\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load the various input files\n",
    "    readme_text = \"\"\n",
    "    if os.path.exists(readme_path):\n",
    "        with open(readme_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            readme_text = f.read().strip()\n",
    "\n",
    "    fault_description_xml = \"\"\n",
    "    if os.path.exists(fault_description_path):\n",
    "        with open(fault_description_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            fault_description_xml = f.read().strip()\n",
    "\n",
    "    groundtruth_entities = load_lines_from_file(groundtruth_path)\n",
    "    faulty_entities = load_lines_from_file(faulty_path)\n",
    "\n",
    "    reference_embeddings = generate_entity_embeddings(groundtruth_entities)\n",
    "    faulty_embeddings = generate_entity_embeddings(faulty_entities)\n",
    "\n",
    "    # Detect faults\n",
    "    faults = detect_faults(reference_embeddings, faulty_embeddings)\n",
    "\n",
    "    gap_report_lines = []\n",
    "    improvement_lines = []\n",
    "\n",
    "    print(\"Processing specifications...\")\n",
    "    if faults:\n",
    "        gap_report_lines.append(\"--- Fault Analysis ---\")\n",
    "        for f in faults:\n",
    "            fault_topics = [e['text'] for e in f['entities']]\n",
    "            gap_report_lines.append(f\"Fault type: {f['type']}, Topics: {fault_topics}\")\n",
    "        gap_report_lines.append(\"\")\n",
    "\n",
    "        # Generate improvement suggestions\n",
    "        suggestions = suggest_improvements_batch(faults, readme_text, fault_description_xml)\n",
    "        improvement_lines.append(\"--- Suggestions for Improvement ---\")\n",
    "        for s in suggestions:\n",
    "            improvement_lines.append(f\"Fault Type: {s['fault_type']}\")\n",
    "            improvement_lines.append(f\"Topics: {s['topics']}\")\n",
    "            improvement_lines.append(\"Suggestion:\\n\" + s['suggestion'] + \"\\n\")\n",
    "    else:\n",
    "        gap_report_lines.append(\"No faults detected.\\n\")\n",
    "        improvement_lines.append(\"No improvements needed.\\n\")\n",
    "\n",
    "    with open(report_file_path, \"w\", encoding=\"utf-8\") as report_file:\n",
    "        report_file.write(\"\\n\".join(gap_report_lines))\n",
    "\n",
    "    with open(improvements_file_path, \"w\", encoding=\"utf-8\") as imp_file:\n",
    "        imp_file.write(\"\\n\".join(improvement_lines))\n",
    "\n",
    "    print(\"Processing complete. Reports generated.\")\n",
    "    print(f\"Gap report: {report_file_path}\")\n",
    "    print(f\"Improvement suggestions: {improvements_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
